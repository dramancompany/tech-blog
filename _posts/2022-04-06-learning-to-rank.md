---
layout: "post"
title: "Learning to Rank"
author: "mgpark"
date: "2022-04-06"
categories: 
  - "ailab"
---

ì•ˆë…•í•˜ì„¸ìš”!ğŸ˜€Â  ë¹…ë°ì´í„°ì„¼í„° AI Lab ë°•ë¯¼ê·œì…ë‹ˆë‹¤.

ì €ë²ˆë‹¬ì— ì‘ì„±í•œ Document Understanding ê¸€ì—ì„œ ì €í¬ ë¹…ë°ì´í„°ì„¼í„°ì—ì„œëŠ” Recommendation Systemì„ ì—°êµ¬í•˜ê³  ìˆë‹¤ê³  í–ˆì—ˆëŠ”ë°ìš”. ì´ë²ˆ ê¸€ì—ì„œëŠ” Recommendation Systemì—ì„œ ì‚¬ìš©ë˜ëŠ” **Learning to Rank(LTR)**ì— ëŒ€í•´ ì†Œê°œí•˜ë ¤ê³  í•©ë‹ˆë‹¤.

## Learning to Rank(LTR)ì´ë€ ë¬´ì—‡ì¼ê¹Œ?

Learning to Rank(LTR)ë€ Ranking Systemì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ë¡ ì„ ë§í•©ë‹ˆë‹¤.

Ranking Systemì€ ì•„ë˜ì™€ ê°™ì€ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.

- **Search Engines** : êµ¬ê¸€ ê°™ì€ ì›¹í˜ì´ì§€ì—ì„œ ê²€ìƒ‰ ì‹œ ë‚˜ì˜¤ëŠ” ê²°ê³¼ë“¤(ë¬¸ì„œ)ë¥¼ ì—°ê´€ì„±ì´ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬í•˜ê¸°.

![](/images/5UabfeBH5b.png)

Figure 1. Searching â€œartificial intelligenceâ€ in Google Search Engines.

- **Recommendation System** : ìœ ì €ì˜ íŠ¹ì„±ì— ë”°ë¼ ê°€ì¥ ìœ ì €ì—ê²Œ ì•Œë§ì„ ê²ƒ ê°™ì€ Itemì„ ì¶”ì²œ ì ìˆ˜ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ê¸°.

![](/images/4WudIwqr1D.png)

Figure 2. Personalized ranked contents in Netflix.

Ranking Systemì€ Query(ê²€ìƒ‰ì–´, ìœ ì €ì˜ íŠ¹ì„± ë“±)ì— ë”°ë¼ Itemë“¤(ë¬¸ì„œ, ì»¨í…ì¸  ë“±)ì´ ì—°ê´€ì„± ë†’ì€ ìˆœì„œë¡œ ì •ë ¬ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë¼ê³  ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

LTRì€ ì´ëŸ¬í•œ Ranking Systemì„ **ë¨¸ì‹ ëŸ¬ë‹ì— ì ìš©í•˜ì—¬ Queryì™€ Itemì˜ ì—°ê´€ì„± ì ìˆ˜ë¥¼ ì˜ˆì¸¡**í•©ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì„ ì‚¬ìš©í•˜ê¸° ì´ì „ì—ëŠ” **Vector Space Model, Probabilistic model**ê³¼ ê°™ì€ ì „í†µì  ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ Itemì˜ Rankingì„ êµ¬í–ˆìŠµë‹ˆë‹¤.

## ë¨¸ì‹ ëŸ¬ë‹ ì´ì „ Model

1\. Vector Space Model

- TF-IDF(ì—¬ëŸ¬ ë¬¸ì„œ ì•ˆì—ì„œ ë‹¨ì–´ì˜ ìƒëŒ€ì ì¸ ì¤‘ìš”ë„)ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ Queryì™€ Item(ë¬¸ì„œ)ë¥¼ ê°ê° ì„ë² ë”©í•˜ì—¬ Query-Item relevance score(cosine similarity)ë¥¼ êµ¬í•˜ê³  ë†’ì€ ìœ ì‚¬ë„ ê°’ì„ ê°€ì§€ëŠ” Itemì„ ìƒìœ„ì— ìœ„ì¹˜ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

2\. Probabilistic Model

- BM25 : TFì™€ IDF, ë¬¸ì„œ ê¸¸ì´ ë“±ì„ ê°€ì§€ê³  Queryì™€ Item(ë¬¸ì„œ)ì˜ relevancyë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ TF-IDFë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì„ ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡ŒìŠµë‹ˆë‹¤.
- Language model : Likelihood ë°©ë²•ì„ í™œìš©í•˜ì—¬ Queryê°€ Itemì˜ ì„ì˜ì˜ ìƒ˜í”Œë¡œ ê´€ì°°ë  í™•ë¥ ì— ë”°ë¼ Item ìˆœìœ„ë¥¼ êµ¬í•©ë‹ˆë‹¤.

## Rankingì— ì‚¬ìš©ë˜ëŠ” Metric

Rankingì—ì„œëŠ” ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ Itemì— ëŒ€í•œ ìˆœìœ„ë¥¼ ì˜ ë§¤ê¸°ëŠ”ì§€ ì¸¡ì •í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ metric(í‰ê°€ ì§€í‘œ)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

### MRR(Mean Reciprocal Rank)

![](/images/aR1jKtdBxe.png)

ê° Queryë§ˆë‹¤ 1ìœ„ Itemì„ ë§ì¶˜ ì ìˆ˜ë¥¼ í‰ê· í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. Queryì— ëŒ€í•´ ì—¬ëŸ¬ Itemë“¤ì´ rankëì„ ë•Œ test setì˜ ì •ë‹µ(1ìœ„)ì¸ Itemì´ ëª‡ìœ„ì— ìˆëŠ”ê°€ì— ë”°ë¼ reciprocal rankê°€ ê³„ì‚°ë©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ëª¨ë“  Queryì˜ reciprocal rankë¥¼ í‰ê· í•˜ë©´ MRR ì ìˆ˜ê°€ ì‚°ì¶œë©ë‹ˆë‹¤.

í•´ë‹¹ ë°©ë²•ì€ 1ìœ„ì˜ itemì˜ ìœ„ì¹˜ë§Œ íŒŒì•…í•˜ê¸°ì— ë‹¤ë¥¸ Itemì˜ ê´€ë ¨ì„±ì€ ë¬´ì‹œí•œë‹¤ëŠ” í•œê³„ì ì„ ê°€ì§‘ë‹ˆë‹¤.

## Precision at k

![]({{ site.baseurl }}/images/RspfzvROsY.png)

Precisionì€ ì¶”ì²œëœ top kì˜ Item ì¤‘ ê´€ë ¨ì„± ìˆëŠ” ì•„ì´í…œì˜ ë¹„ìœ¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. í•´ë‹¹ metricì€ ê´€ë ¨ì´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ë§Œ íŒë‹¨í•©ë‹ˆë‹¤. ì¦‰, rankì— ëŒ€í•œ ì ìˆ˜ëŠ” ê³„ì‚°í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” í•œê³„ì ì„ ê°€ì§‘ë‹ˆë‹¤.

### nDCG(normalized Discounted Cumulative Gain)

![](/images/ck7nPEFOWS.png)

![](/images/8a7Pw2DKBQ.png)

![](/images/mBtK1QqOAz.png)

![](/images/LC0hEv6jin.png)

nDCGëŠ” MRRê³¼ Precisionì˜ ë‹¨ì ì„ ëª¨ë‘ ë³´ì™„í•œ metricì…ë‹ˆë‹¤.

- DCG
    - DCGëŠ” Ranking ìˆœì„œì— ë”°ë¼ ì ì  ë¹„ì¤‘ì„ ì¤„ì—¬ discountedëœ ê´€ë ¨ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ìˆœìœ„ê°€ í•˜ìœ„ë¡œ ê°ˆ ìˆ˜ë¡ íŒ¨ë„í‹°ë¥¼ ì¤€ë‹¤ê³  ë³´ë©´ ë©ë‹ˆë‹¤. Ranking ìˆœì„œë³´ë‹¤ ê´€ë ¨ì„±ì— ë¹„ì¤‘ì„ ë‘ê³  ì‹¶ìœ¼ë©´ ìœ„ ê³„ì‚°ì‹ ì¤‘ì— ë‘ ë²ˆì§¸ ì‹ì„ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

- IDCG â†’ nDCG
    - DCGëŠ” Ranking ê²°ê³¼ ê¸¸ì´ì¸ pì— ë”°ë¼ ê°’ì´ ë§ì´ ë³€í•˜ê¸°ì— ì¼ì • ìŠ¤ì¼€ì¼ì˜ ê°’ì„ ê°€ì§€ë„ë¡ normalizeê°€ í•„ìš”í•©ë‹ˆë‹¤. IDCGë¥¼ êµ¬í•˜ì—¬ ì´ë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - DCGë¥¼ IDCGë¡œ ë‚˜ëˆ„ë©´ nDCGë¥¼ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## LTRì„ ìœ„í•œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸

![]({{ site.baseurl }}/images/BIQEGyzRqq.png)

Figure 3. Learning to Rank framework.

Figure 3ì€ LTRì˜ frameworkì…ë‹ˆë‹¤. nê°œì˜ Queryì— ëŒ€í•´ì„œ ê° Itemì— ëŒ€í•œ mê°œì˜ feature(x)ê°€ ìˆê³ , nê°œì˜ relevance score y(ì˜ˆ. ìœ ì €ì˜ í´ë¦­ ìˆ˜, í‰ì  ë“±)ì´ ìˆìŠµë‹ˆë‹¤. ì´ í•™ìŠµë°ì´í„°ë¡œ ëª¨ë¸ hë¥¼ ë§Œë“¤ì–´ í…ŒìŠ¤íŠ¸ë°ì´í„°ë¥¼ ì…ë ¥í–ˆì„ ë•Œ relevance scoreë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. LTRì—ì„œ ì¤‘ìš”í•œ ê²ƒì€ â€œ**ì–´ë–¤ ì†ì‹¤í•¨ìˆ˜(Loss Function)ì„ í™œìš©í•´ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ”ê°€**â€ ì…ë‹ˆë‹¤.

### Loss Function

#### **Point-wise**

í•œê°œì˜ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ëœ yê°’ê³¼ ground truth yê°’ì— ëŒ€í•œ ì°¨ì´ë§Œ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. MSE(Mean Square Error) lossê°€ ëŒ€í‘œì ì¸ ì˜ˆë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### **Pair-wise**

ë‘ê°œì˜ Itemì„ ë¹„êµí•´ ì–´ëŠ Itemì´ Queryì™€ ê°€ì¥ ìœ ì‚¬í•œì§€ íŒë‹¨í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. Point-wise ë°©ë²•ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” í…ŒìŠ¤íŠ¸ë°ì´í„°ì— ëŒ€í•œ ground truthê°’ì´ ëª¨ë‘ ì ˆëŒ€ì ì´ì–´ì•¼ í•˜ëŠ”ë° í˜„ì‹¤ì—ì„œëŠ” ê·¸ëŸ¬í•œ ë°ì´í„°ë¥¼ ì°¾ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤. ì´ì— ëŒ€í•œ í•´ê²°ì±…ìœ¼ë¡œ Pair-wise ë°©ë²•ì€ ë‘ Item ì‚¬ì´ì˜ ìƒëŒ€ì ì¸ relevancyë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

- RankNet : Binary Cross Entropy lossë¥¼ ì‚¬ìš©í•˜ì—¬ Pair-wiseë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
- LambdaRank : ë†’ì€ rankì— í•´ë‹¹í•˜ëŠ” Itemì€ ë†’ì€ gradientsë¥¼ ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.
- LambdaMART: Grdient Boosting ë°©ë²•ì„ í™œìš©í•˜ì—¬ LambdaRankë³´ë‹¤ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ëƒ…ë‹ˆë‹¤.

#### **List-wise**

í•´ë‹¹ ë°©ë²•ì€ Pairë¥¼ ë„˜ì–´ì„œ Item listì— ëŒ€í•œ ëª¨ë“  relevancyë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. Ranking metricì„ ìµœëŒ€í™”í•˜ëŠ” ë°©ë²•ì´ê¸°ì— ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- LambdaRank, LambdaMARTëŠ” List-wiseì—ì„œë„ ì‚¬ìš©ê°€ëŠ¥í•©ë‹ˆë‹¤.
- SoftRank : ê° Itemì— ëŒ€í•œ rank í™•ë¥  ë¶„í¬ë¥¼ êµ¬í•©ë‹ˆë‹¤.
- ListNet : Plackett-Luce modelë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  rank ì¡°í•©(permutation)ì— ëŒ€í•œ lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

## ìµœì‹  LTR ì—°êµ¬ë“¤

ë”¥ëŸ¬ë‹ì„ LTRì— ì ìš©í•˜ëŠ” ìµœì‹  ì—°êµ¬ë“¤ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

### **GSF(Groupwise Scoring Function)**

![](/images/2efVal3Wqh.png)

Figure 4. GSF architecture

GSF\[2\]ëŠ” ì—¬ëŸ¬ Item featureë“¤(x1, x2, x3)ì— ëŒ€í•œ ì¡°í•©(\[x1, x2\], \[x1, x3\], â€¦)ì„ ë§Œë“¤ê³  MLPë¥¼ í†µê³¼ì‹œì¼œ ê° Itemì— ëŒ€í•œ outputë“¤ì„ í•©ì‚°í•˜ì—¬ í•˜ë‚˜ì˜ outputìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.

### **seq2slate**

![](/images/GgiRpvwZd2.png)

Figure 5. seq2slate architecture

seq2slate\[3\]ëŠ” Point Networkì˜ varientì™€ ì¡°í•©ëœ RNNì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

- ì—¬ê¸°ì„œ Pointer NetworkëŠ” ê²°ê³¼ ì¶œë ¥ ì‹œ ì…ë ¥ ë¬¸ì¥ ì¤‘ ì •ë‹µì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì˜ indexë¥¼ ì¶œë ¥í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤. seq2seqì˜ ë³€í˜•ìœ¼ë¡œ ê³ ì •ëœ ê¸¸ì´ì˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” ê¸°ì¡´ RNNê³¼ ë‹¬ë¦¬ ì…ë ¥ì— ë”°ë¼ ìœ ë™ì ì¸ ì¶œë ¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### **DLCM(Deep Listwise Context Model)**

![](/images/jE3r2J3HgF.png)

Figure 6. DLCM architecture

DLCM\[1\]ì€ Queryì™€ Itemì˜ featureë¥¼ ì—­ë°©í–¥ìœ¼ë¡œ GRUì— í†µê³¼ì‹œí‚¨ ê° ê²°ê³¼ì™€ ë§ˆì§€ë§‰ ê²°ê³¼ì— ëŒ€í•´ local ranking functionì„ ì ìš©í•˜ì—¬ scoreë¥¼ ì–»ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

### **Context-Aware Ranker**

![](/images/ugMGQuA07h.png)

Figure 7. Context-Aware Ranker architecture

Context-Aware Ranker\[6\]ëŠ” ê° Queryì™€ Itemì— ëŒ€í•œ feature vectorë¥¼ í•˜ë‚˜ë¡œ ë§Œë“¤ì–´ (FF)Feed Forward Networkì— ì…ë ¥í•˜ê³ , transformerë¥¼ ê±°ì³ ë‹¤ì‹œ FFì— í†µê³¼ì‹œí‚¨ í›„ ìµœì¢… scoreë¥¼ ì–»ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

LTR ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì¸ MSLR-WEB30Kì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥(SOTA)ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.

## ë§ˆë¬´ë¦¬ í•˜ë©°

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” LTRì˜ ê¸°ë³¸ì ì¸ ê°œë…ê³¼ ìµœì‹ ì—°êµ¬ë¥¼ ì‚´í´ë´¤ìŠµë‹ˆë‹¤. ë“œë¼ë§ˆì•¤ì»´í¼ë‹ˆì—ì„œëŠ” LTRì˜ ìµœì‹ ì—°êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì¸ì¬ ì¶”ì²œ ì„œë¹„ìŠ¤, ê´‘ê³  ì¶”ì²œ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. AI Labì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ LTRì„ ì–´ë–»ê²Œ ì ìš©í•˜ê³  ìˆëŠ”ì§€ëŠ” ë‹¤ìŒì— ê³µìœ í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì€ ëŒ“ê¸€ì„ í†µí•´ ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ë¶€ì¡±í•œ ê¸€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ë‹¤ìŒë²ˆì— ë” ì¢‹ì€ ê¸€ë¡œ ì°¾ì•„ëµ™ê² ìŠµë‹ˆë‹¤ ğŸ¤—

## Reference

\[1\] Ai, Q., Bi, K., Guo, J., & Croft, W. B. (2018, June). Learning a deep listwise context model for ranking refinement. InÂ _The 41st international ACM SIGIR conference on research & development in information retrieval_ (pp. 135-144).

\[2\] Ai, Q., Wang, X., Bruch, S., Golbandi, N., Bendersky, M., & Najork, M. (2019, September). Learning groupwise multivariate scoring functions using deep neural networks. InÂ _Proceedings of the 2019 ACM SIGIR international conference on theory of information retrieval_Â (pp. 85-92).

\[3\] Bello, I., Kulkarni, S., Jain, S., Boutilier, C., Chi, E., Eban, E., ... & Meshi, O. (2018). Seq2slate: Re-ranking and slate optimization with rnns.Â _arXiv preprint arXiv:1810.02019._

\[4\] [https://en.wikipedia.org/wiki/Learning\_to\_rank](https://en.wikipedia.org/wiki/Learning_to_rank)

\[5\] Liu, T. Y. (2009). Learning to rank for information retrieval.Â _Foundations and TrendsÂ® in Information Retrieval_,Â _3_(3), 225-331.

\[6\] Pobrotyn, P., Bartczak, T., Synowiec, M., BiaÅ‚obrzeski, R., & Bojar, J. (2020). Context-aware learning to rank with self-attention.Â _arXiv preprint arXiv:2005.10084_.
